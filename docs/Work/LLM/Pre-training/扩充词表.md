# 基于SentencePiece扩充LLaMa中文词表

LLM 的词表与tokenization都基于SentencePiece实现，目前主流的分词算法已经被SentencePiece实现了，详情可见[SentencePiece](https://github.com/google/sentencepiece)

